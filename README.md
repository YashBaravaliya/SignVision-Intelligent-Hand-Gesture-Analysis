# SignVision: Intelligent Hand Gesture Analysis

## Overview

SignVision is an intelligent hand gesture analysis system designed for recognizing and interpreting sign language gestures. The project utilizes the MediaPipe library for accurate hand tracking and a machine learning model for gesture classification.

## Features

- Real-time hand gesture recognition using a webcam.
- Model training for custom hand gestures.
- Prediction of gestures based on a trained model.

## Screenshots

### Main GUI

![Main GUI](/images/gui.png)

## Setup

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/YashBaravaliya/SignVision-Intelligent-Hand-Gesture-Analysis
   ```

2. Navigate to the project directory:

   ```bash
   cd SignVision-Intelligent-Hand-Gesture-Analysis
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

### Training Custom Signs

To train your own sign language gestures:

1. Prepare your training data:
   - Create a folder inside the `data` directory for each sign.
   - Collect images or frames for each sign and save them in their respective folders.

2. Train the model:

   ```bash
   python train.py --data_folder path/to/data --model_folder path/to/save/model --model_name your_model_name.p
   ```

### Usage

#### Performing Hand Gesture Recognition

To perform real-time hand gesture recognition:

```bash
python app.py
```

The application will use the trained model to recognize hand gestures through your webcam.

#### Predicting Gestures

To predict gestures using a trained model:

```bash
python prediction.py --model_path path/to/model.p --data_txt path/to/data.txt
```

## Contributing

Contributions are welcome! If you have any ideas, bug reports, or feature requests, please [open an issue](https://github.com/YashBaravaliya/SignVision-Intelligent-Hand-Gesture-Analysis/issues).

